## Chapter 5

> 程序优化的第一步是消除不必要的工作，让代码尽可能有效地执行所期望地任务。这包括消除不必要地函数调用、条件测试和内存引用。这些优化不依赖于目标机器地任何具体属性。
>
> 了解了处理器地运作，我们就可以进行程序优化地第二步，利用处理器提供地指令级并行（instruction-level parallelism）能力，同时执行多条指令。
>
> 即时是最好地编译器也受到妨碍优化的因素（optimization blocker）的阻碍，妨碍优化的因素就是程序行为中那些严重依赖于执行环境的方面。
>
> 正如我们会看到的，常常通过确认关键路径（critical path）来决定执行一个循环所需要地时间（或者说，至少是一个时间下界）。所谓关键路径是在循环地反复执行过程中形成地数据相关链。

### 5.1 优化编译器地能力和局限性 

> 我们会发现可以写出的 C 代码，即使用 `-O` 选项编译得到的性能，也比用可能的最高的优化等级编译一个更原始的版本的到的性能好。
>
> 这种两个指针可能指向同一个内存位置地情况称为内存别名使用（memory aliasing）。
>
> 包含函数调用的代码可以用一个称为内联函数替换（inline substitution，或者简称“内联（inlining）“）的过程进行优化，此时，将函数调用替换为函数体。
>
> 用内联函数替换优化函数调用
>
> GCC 的最近版本会尝试进行这种形式的优化，要么是被命令行选项“-finline”指示时，要么使用优化等级 `-O1` 或者更高的等级时。遗憾的是，GCC 只尝试在单个文件中定义的函数的内联。这就意味着它将无法应用于常见的情况，即一组库函数在一个文件中被定义，却被其他文件内的函数所调用。
>
> 在某些情况下，最好能阻止编译器执行内联替换。如果一个函数调用已经用内联替换优化过了，那么任何对这个调用进行追踪或设置断点的尝试都会失败。还有一种情况是用代码剖析的方式来评估程序性能。用内联替换消除的函数调用是无法被正确剖析的。

实测需要使用 `-O2` 会优化成内联函数。

### 5.2 表示程序性能

> 我们引入度量标准每元素的周期数（Cycles Per Element，CPE），作为一种表示程序性能并指导我们改进代码的方法。
>
> 处理器活动的顺序是由时钟控制的，时钟提供了某个频率的规律信号，通常用千兆赫兹（GHz），即十亿周期每秒来表示。例如，当表明一个系统有“4GHz”处理器，这表示处理器时钟运行频率为每秒 4*10^9 个周期。每个时钟周期的时间是时钟频率的倒数。通常是以纳秒（nanosecond，1 纳秒等于 10^-9 秒）或皮秒（picosecond，1 皮秒等于 10^-12 秒）为单位的。从程序员的角度来看，用时钟周期来表示度量标准要比用纳秒或皮秒来表示有帮助得多。用时钟周期来表示，度量值表示的是执行了多少条指令，而不是时钟运行得有多快。
>
> 这些项中的系数称为每元素的周期数（简称 CPE）的有效值。注意，我们更愿意用每个元素的周期数而不是每次循环的周期数来度量，这是因为像循环展开这样的技术使得我们能够用较少的循环完成计算，而我们最终关心的是，对于给定的向量长度，程序运行的速度如何。我们将精力集中在减小计算的 CPE 上。
>
> 什么是最小二乘拟合
>
> 对于一个数据点（x~1~，y~1~），...，（x~n~，y~n~）的集合，我们常常试图画一条线，它能最接近于这些数据代表的 X-Y 趋势。使用最小二乘拟合，寻找一条形如 y=mx+b 的线，使得下面这个误差度量最小：
> $$
> E(m,b)=\sum\limits_{i=1,n}(mx_i+b-y_i)^2
> $$
> 将 E（m，b） 分别对 m 和 b 求导，把两个导数函数设置为 0，进行推导就能得出计算 m 和 b 的算法。

### 5.4 消除循环的低效率

> 这个优化是一类常见的优化的一个例子，称为代码移动（code motion）。这类优化包括识别要执行多次（例如在循环里）但是计算结果不会改变的计算。因而可以将计算移动到代码前面不会被多次求值的部分。
>
> 这个实例说明了编程时一个常见的问题，一个看上去无足轻重的代码片段有隐藏的渐近低效率（asymptotic inefficiency）。大型编程项目中出现这样问题的故事比比皆是。一个有经验的程序员工作的一部分就是避免引入这样的渐近低效率。

### 5.5 减少过程调用

> 像我们看到过的那样，过程调用会带来开销，而且妨碍大多数形式的程序优化。

### 5.6 消除不必要的内存引用

> 我们可以开电脑每次迭代时，累计变量的数值都要从内存读出再写入到内存。这样的读写很浪费；

### 5.7 理解现代处理器

> 为了理解改进性能的方法，我们需要理解现代处理器的微体系结构。在代码级上，看上去似乎是一次执行一条指令，每条指令都包括从寄存器或内存取值，执行一个操作，并把结果存回到一个寄存器或内存位置。在实际的处理器中，是同时对多条指令求值的，这个现象称为指令级并行。现代微处理器取得的了不起的功绩之一是：它们采用复杂而奇异的微处理器结构，其中，多条指令可以并行地执行，同时又呈现出一种简单的顺序执行指令的表象。
>
> 我们会发现两种下界描述了程序的最大性能。当一系列操作必须按照严格顺序执行时，就会遇到延迟界限（latency bound），因为在下一条指令开始之前，这条指令必须结束。当代码中的数据相关限制了处理器利用指令级并行的能力时，延迟界限能够限制程序性能。吞吐量界限（throughput bound）刻画了处理器功能单元的原始计算能力。这个界限是程序性能的终极限制。

#### 5.7.1 整体操作

> 整个设计有两个主要部分：指令控制单元（Instruction Control Unit，ICU）和执行单元（Execution Unit，EU）。前者负责从内存中读出指令序列，并根据这些指令序列生成一组针对程序数据的基本操作；而后者执行这些操作。
>
> ICU 从指令高速缓存（instruction cache）中读取指令，指令高速缓存是一个特殊的高速储存器，它包含最近访问的指令。
>
> 指令译码逻辑接收实际的程序指令，并将它们转换成一组基本操作（有时称为微操作）。
>
> 举个例子，我们的 Intel Core i7 Haswell 参考机有 8 个功能单元，编号为 0~7。下面部分列出了每个单元的功能：
>
> 0：整数运算、浮点乘、整数和浮点数除法、分支
>
> 1：整数运算、浮点加、整数乘、浮点乘
>
> 2：加载、地址计算
>
> 3：加载、地址计算
>
> 4：存储
>
> 5：整数运算
>
> 6：整数运算
>
> 7：存储、地址计算
>
> 在上面的列表中，“整数运算”是指基本的操作，比如加法、位级操作和位移。
>
> 在 ICU 中，退役单元（retirement unit）记录正在进行的处理，并确保它遵守机器级程序的顺序语义。我们的图中展示了一个寄存器文件，它包含整数、浮点数和最近的 SSE 和 AVX 寄存器，是退役单元的一部分，因为退役单元控制这些寄存器的更新。指令译码时，关于指令的信息被放置在一个先进先出的队列中。这些信息会一直保持在队列中，直到发生以下两个结果中的一个。首先，一旦一条指令的操作完成了，而且所有引起这条指令的分支点也都被确认为预测正确，那么这条指令就可以退役（retired）了，所有对程序寄存器的更新都可以被实际执行了。另一方面，如果引起该指令的某个分支点预测错误，这条指令会被清空（flushed），丢弃所有计算出来的结果。通过这种方法，预测错误就不会改变程序的状态了。
>
> 控制操作数在执行单元间传送的最常见的机制称为寄存器重命名（register renaming）。

#### 5.7.2 功能单元的性能

> 每个运算都是由以下的这些数值来刻画的：一个是延迟（latency），它表示完成运算所需要的总时间；另一个是发射时间（issue time），它表示两个连续的同类型的运算之间需要的最小时钟周期数；还有一个是容量（capacity），它表示能够执行该运算的功能单元的数量。
>
> 一个典型的浮点加法器包含三个阶段（所以有三个周期的延迟）：一个阶段处理指数值，一个阶段将小数相加，而另一个阶段对结果进行摄入。发射时间为 1 的功能单元被称为完全流水线化（fully pipelined）：每个时钟周期可以开始一个新的运算。
>
> 表达发射时间的一种更常见的方法是指明这个功能单元的最大吞吐量，定义为发射时间的倒数。具有多个功能单元可以进一步提高吞吐量。对一个容量为 C，发射时间为 I 的操作来说，处理器可能获得的吞吐量为每时钟周期 C/I 个操作。

#### 5.7.3 处理器操作的抽象模型

> 对于形成循环的代码片段，我们可以将访问到的寄存器分为四类：
> 只读：这些寄存器只用作源值，可以作为数据，也可以用来计算内存地址，但是在循环中它们是不会被修改的。
> 只写：这些寄存器作为数据传送操作的目的。
> 局部：这些寄存器在循环内部被修改和使用，迭代与迭代之间不相关。
> 循环：对于循环来说，这些寄存器既作为源值，又作为目的，一次迭代中产生的值会在另一个迭代中用到。
> 正如我们会看到的，循环寄存器之间的操作链决定了限制性能的数据相关。
> 数据流表示中的关键路径提供的只是程序需要周期数的下界。还有其他的一些因素会限制性能，包括可用的功能单元的数量和任何一步中功能单元之间能够传递数据值的数量。

对练习题 5.5 的代码

```c
double poly(double a[], double x, long degree)
{
    long i;
    double result = a[0];
    double xpwr = x;
    for (i = 1; i <= degree; i++) {
        result += a[i] * xpwr;
        xpwr = x * xpwr;
    }
    return result;
}
```

使用优化级别 `-O2` 进行汇编得到循环中代码

```assembly
.L3:
	vmulsd (%rax), %xmm1, %xmm3	# 0
	addq $8, %rax				# 1
	cmpq %rdx, %rax				# 2
	vmulsd %xmm0, %xmm1, %xmm1	# 3
	vaddsd %xmm3, %xmm2, %xmm2	# 4
	jne .L3
```

编译器对代码进行了顺序上的优化，基于功能单元的数量猜测原因（非超标量处理器）为：

- `#1` 和 `#2` 为整数运算，在浮点数乘法 5 个周期期间，它们所占的 1 个周期并且多达 4 个支持整数运算的功能单元能够快速并行处理；就算占用了浮点数运算单元也不会增加太多延迟；
- 编译器将 `#4` 和 `#3` 本该的顺序对调了，假设 `#4` 在前；虽然浮点乘有 2 个功能单元，但是浮点加只有功能单元 1 才支持；~~假设 `#0` 占用了功能单元 1，那么浮点数加法 `#4` 需要等待功能单元 1 结束才可以计算，而 `#3` 同样要等待 `#4` 执行了，才被加载到功能单元 0 中；~~

对于问题 B 中为何 CPE 为 5.00 的（超标量处理器）解释为：

因为有 2 个浮点乘的功能单元，所以 `#0` 和 `#3` 可以在一次迭代中并行；由于 `#4` 的值并不影响下一次迭代（不需要等它得出结果），可以放在下一次迭代中（这也是为什么要放在最后）；由于浮点加和浮点乘的发射时间为 1 即完全流水线化的，在完成 5 周期的浮点乘之前，3 周期的浮点加已经从流水线中结束（可能是可行的）；类似于书中，在图 5-14a 中，如果操作符不属于某个循环寄存器之间的相关链，那么就把它们标识成白色，并且最终从数据流图中消除了（去除“局部”寄存器）。

### 5.8 循环展开

> 循环展开是一种程序变换，通过增加每次迭代计算的元素的数量，减少循环的迭代次数。循环展开能够从两个方面改进程序的性能。首先，它减少了不直接有助于程序结果的操作的数量，例如循环索引计算和条件分支。第二，它提供了一些方法，可以进一步变化代码，减少整个计算中关键路径上的操作数量。
>
> 让编译器展开循环
>
> 编译器可以很容易地执行循环展开。只要优化级别设置得足够高，许多编译器都能例行公事地做到这一点。用优化等级 3 或更高等级调用 GCC，它就会执行循环展开。

文中浮点数乘法循环展开，第二次展开的乘法依然第一次的结果，所以总的来说，乘法的关键路径并没有改变；也就是说，不能充分利用运算单元中有两个浮点乘单元（此外，除了除法以外，功能单元都是完全流水线化的）；

如果分别计算两次展开的乘积，然后再结尾将两个乘积相乘，应该就可以充分利用并行；

### 5.9 提高并行性

> 在此，程序的性能是受运算单元的延迟限制的。现在我们要考察打破这种顺序相关，得到比延迟界限更好性能的方法。

#### 5.9.1 多个累计变量

> 对于一个可结合和可交换的合并运算来说，比如说整数加法或乘法，我们可以通过将一组合并运算分割成两个或更多的部分，并在最后合并结果来提高性能。
>
> 可以看到，当 k 值足够大时，程序在所有情况下几乎都能达到吞吐量界限。整数加在 k = 7 时达到的 CPE 为 0.54，接近由两个加载单元导致的吞吐量界限 0.50。整数乘和浮点加在 k >= 3 时达到的 CPE 为 1.01，接近由它们的功能单元设置的吞吐量界限 1.00。浮点乘在 k >= 10 时达到的 CPE 为 0.51，接近由两个浮点乘法器和两个加载单元设置的吞吐量界限 0.50。值得注意的是，即使乘法是更加复杂的操作，我们的代码在浮点乘上达到的吞吐量几乎是浮点加可以达到的两倍。
>
> 通常，只有保持能够执行该操作的所有功能单元的流水线都是满的，程序才能达到这个操作的吞吐量界限。对延迟为 L，容量为 C 的操作而言，这就要求循环展开因子 k >= C * L。
>
> 另一方面，浮点乘法和加法不是可结合的。

#### 5.9.2 重新结合变换

> 现在来探讨另一种打破顺序相关从而使性能提高到延迟界限之外的方法。
>
> 在 combine5 种，合并是以下面这条语句来实现的
>
> ```c
> acc = (acc OP data[i]) OP data[i+1];
> ```
>
> 而在 combine7 中，合并是以这条语句来实现的
>
> ```c
> acc = acc OP (data[i] OP data[i+1]);
> ```
>
> 差别仅在于两个括号是如何放置的。我们称之为重新结合变换（reassociation transformation）。
>
> 总的来说，重新结合变化能够减少计算中关键路径上操作的数量，通过更好地利用功能单元地流水线能力得到更好地性能。大多数编译器不会尝试对浮点运算做重新结合，因为这些运算不保证是可结合地。当前地 GCC 版本会对整数运算执行重新结合，但不是总有好地效果。通常，我们发现循环展开和并行地累积在多个值中，是提高程序性能地更可靠地方法。

原来右边的元素 `data[i+1]` 需要等待左边计算的结果，成为了阻碍优化的因素；如果先计算右边，则它们只是从内存中取出来进行计算，是互不相干的；

实际上，这也体现了赋值运算符的确是效率高的，例如写成

```c
acc += acc + (data[i] + data[i+1])
```

尤其是在循环中。

> 用向量指令达到更高的并行度
>
> 目前的 AVX 向量寄存器长为 32 字节，因此每一个都可以存放 8 个 32 位数或 4 个 64 位数，这些数据既可以是整数也可以是浮点数。AVX 指令可以对这些寄存器执行向量操作，比如并行执行 8 组数值或 4 组数值的加法或乘法。我们看到，一条指令能够产生对多个数据值的计算，因此称为 `SIMD`（ “Single Instruction，Multiple-Data” 单指令多数据）。

### 5.10 优化合并代码的结果小结

> 使用多项优化技术，我们获得的 CPE 已经接近了 0.50 和 1.00 的吞吐量界限，只受限于功能单元的容量。与原始代码相比提升了 10~20 倍，且使用普通的 C 代码和标准编译器就获得了所有这些改进。重写代码利用较新的 SIMD 指令得到了将近 4 倍或 8 倍的性能提升。比如单精度乘法，CPE 从初值 11.14 降到了 0.06，整体性能提升超过 180 倍。这个例子说明现代处理器具有相当的计算能力，但是我们可能需要按非常程式化的方式来编写程序以便将这些能力诱发出来。

### 5.11 一些限制因素

> 我们还看到功能单元的吞吐量界限也是程序执行时间的一个下界。也就是说，假设一个程序一共需要 N 个某种运算的计算，而微处理器只有 C 个能执行这个操作的功能单元，而且这些单元的发射时间为 I。那么，这个程序的执行至少需要 N*I/C 个周期。

注意此处与 CPE 区分，后者为每个元素的周期数，所以可以小于 1。

#### 5.11.1 寄存器溢出

> 如果我们的并行度 p 超过了可用的寄存器数量，那么编译器会诉诸溢出（spilling），将某些临时值存放到内存中，通常是在运行时堆栈上分配空间。
>
> 现代 x86-64 处理器有 16 个寄存器，并可以使用 16 个 YMM 寄存器来保存浮点数。一旦循环变量的数量超过了可用寄存器的数量，程序就必须在栈上分配一些变量。

注意遇到函数调用，寄存器是有可能需要放入内存中的。

#### 5.11.2 分支预测和预测错误处罚

> 在一个使用投机执行（speculative execution）的处理器中，处理器会开始执行预测的分支目标处的指令。它会避免修改任何实际的寄存器或内存位置，直到确定了实际的结果。
>
> 对于参考机来说，预测错误处罚是 19 个时钟周期，赌注很高。对于这个问题没有简单的答案，但是下面的通用原则是可用的。
>
> 1. 不要过分关心可预测的分支
>
>    我们已经看到错误的分支预测的影响可能非常大，但是这并不意味着所有的程序分支都会减缓程序的执行。实际上，现代处理器中的分支预测逻辑非常善于辨别不同的分支指令的有规律的模式和长期的趋势。
>
> 2. 书写适合用条件传送实现的代码
>
>    对于本质上无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大地提高程序地性能。

使用

```c
long min = a[i] < b[i] ? a[i] : b[i];
```

即使在 `-Og` 的优化等级下就会使用条件传送指令。

### 5.12 理解内存性能

> 本节会进一步研究涉及加载（从内存读到寄存器）和存储（从寄存器写到内存）操作的程序的性能，只考虑所有的数据都存放在高速缓存中的情况。
>
> 现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的内存操作请求集合。例如，我们的参考机有两个加载单元，每一个可以保存多达 72 个未完成的读请求。它还有一个存储单元，其存储缓冲区能保存最多 42 个写请求。每个这样的单元通常可以每个时钟周期开始一个操作。

#### 5.12.1 加载的性能

> 一个包含加载操作的程序的性能既依赖于流水线能力，也依赖于加载单元的延迟。对于两个加载单元而言，其每个时钟周期只能启动一条加载操作，所以 CPE 不可能小于 0.50。对于每个被计算的元素必须加载 k 个值得应用，我们不可能获得低于 k/2 得 CPE。
>
> 这个函数的 CPE 等于 4.00，是由加载操作的延迟决定的。事实上，这个测试结果与文档中参考机的 L1 级 cache 的 4 周期访问时间是一致的，相关内容将在 6.4 节中讨论。

#### 5.12.2 存储的性能

> 与加载操作一样，在大多数情况下，存储操作能够在完全流水线化的模式中工作，每个周期开始一条新的存储。
>
> 这个示例说明了一个现象，我们称之为写/读相关（write/read dependency）——一个内存读的结果依赖于一个最近的内存写。我们的性能测试表明示例 B 的 CPE 为 7.3。写/读相关导致处理速度下降约 6 个时钟周期。
>
> 存储单元包含一个存储缓冲区，它包含已经被发射到存储单元而又还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。提供这样一个缓冲区，使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行。当一个加载操作发生时，它必须检查存储缓冲区中的条目，看有没有地址相匹配。如果有地址相匹配（意味着在写的字节与在读的字节有相同的地址），它就取出相应的数据条目作为加载操作的结果。
>
> 存储被翻译成两个操作：`s_addr` 指令计算存储操作的地址，在存储缓冲区创建一个条目，并且设置该条目的地址字段。`s_data` 操作设置该条目的数据字段。两个计算是独立执行的，这对程序的性能来说很重要。这使得参考机中不同的功能单元来执行这些操作。特别地，`s_addr` 操作的地址计算必须在 `s_data` 操作之前。`load` 操作必须检查所有未完成的存储操作的地址，在这个操作和 `s_addr` 操作之间创建一个数据相关。这个数据相关是有条件的：如果两个地址相同，`load` 操作必须等待直到 `s_data` 将它的结果存放到存储缓冲区中，但是如果两个地址不同，两个操作就可以独立地进行。
>
> 对于寄存器操作，在指令被译码成操作的时候，处理器就可以确定哪些指令会影响其他哪些指令。另一方面，对于内存操作，只有到加载和存储的地址被计算出来以后，处理器才能确定哪些指令会影响其他的哪些。

### 5.13 应用：性能提高技术

> 我们已经描述了许多优化程序性能的基本策略：
>
> 1. 高级设计
>
>    为遇到的问题选择适当的算法和数据结构。要特别警觉，避免使用那些会渐近地产生糟糕性能的算法或编码技术。
>
> 2. 基本编码原则
>
>    避免限制优化的因素，这样编译器就能产生高效的代码。
>
>    - 消除连续的函数调用。在可能时，将计算移动到循环外。考虑有选择地妥协程序地模块性以获得更大的效率。
>    - 消除不必要的内存引用。引入临时变量来保存中间结果。只有在最后的值计算出来时，才将结果存放到数组和全局变量中。
>
> 3. 低级优化
>
>    结构化代码以利用硬件功能。
>
>    - 展开循环，降低开销，并且使得进一步的优化成为可能。
>    - 通过使用例如多个累计变量和重新结合等技术，找到方法提高指令级并行。
>    - 用功能性的风格重写条件操作，使得编译采用条件数据传送。
>
> 最后要给读者一个忠告，要警惕，在为了提高效率重写程序时避免引入错误。例如，使用循环展开的检查代码需要测试许多不同的循环界限，保证它能够处理最终单步迭代所需要的所有不同的可能的数字。

### 5.14 确认和消除性能瓶颈

> 本节会描述如何使用代码剖析程序（code profiler），这是在程序执行时收集性能数据的分析工具。我们还展示了一个系统优化的通用原则，称为 Amdahl 定律（Amdahl's law）。

#### 5.14.1 程序剖析

> 程序剖析（profiling）运行程序的一个版本，其中插入了工具代码，以确定程序的各个部分需要多少时间。剖析得一个有力之处在于可以在现实的基准数据（benchmark data）上运行实际程序的同时，进行剖析。
>
> Unix 系统提供了一个剖析程序 GPROF。用 GPROF 进行剖析需要 3 个步骤：
>
> 1. 程序必须为剖析而编译和链接。就是在命令行上简单地包括运行时标志 `-pg`。确保编译器不通过内联替换来尝试执行任何优化是很重要的，否则就可能无法正确刻画函数调用。我们使用优化标志 `-Og`，以保证能正确跟踪函数调用。
>
>    ```bash
>    gcc -Og -pg prog.c -o prog
>    ```
>
> 2. 然后程序像往常一样执行，它产生一个文件 gmon.out。
>
> 3. 调用 GPROF 来分析 gmon.out 中数据。
>
>    ```bash
>    gprof prog
>    ```
>
> GPROF 有些属性值得注意：
>
> - 计时不是很准确
>
>   对于那些运行时间少于 1 秒地程序来说，得到的统计数字只能看成是粗略地估计值。
>
> - 假设没有执行内联替换，则调用信息相当可靠。
>
> - 默认情况下，不会显示对库函数地计时。相反，库函数的时间都被计算到调用它们的函数的时间中。

#### 5.14.2 使用剖析程序来指导优化

> 通常会选择桶的个数为质数，以增强哈希函数将关键字均匀分布在桶中的能力。
>
> 通常，假设在有代表性的数据上运行程序，剖析能帮助我们对典型的情况进行优化，但是我们还应该确保对所有可能的情况，程序都有相当的性能。这主要包括避免得到糟糕的渐近性能（asymptotic performance）的算法和坏的编程实践。

### 5.15 小节

> 我们描述了 GPROF，一个标准的 Unix 剖析工具。还有更加复杂完善的剖析程序可用，例如 intel 的 VTUNE 程序开发系统，还有 Linux 系统基本上都有的 VALGRIND。这些工具可以在过程级分解执行时间，估计程序每个基本块（basic block）的性能。（基本块是内部没有控制转移的指令序列，因此基本块总是整个被执行的。）
