## Chapter 4

> 一个处理器支持的指令和指令的字节编码称为它的指令集体系结构（Instruction-Set Architecture, ISA）。
>
> 在计算机科学中，用巧妙的方法在提高性能的同时又保持一个更简单、更抽象模型的功能，这种思想是众所周知的。在 Web 浏览器或者平衡二叉树和哈希表这样的信息检索数据结构中使用缓存，就是这样的例子。
>
> 我们还将介绍一种描述硬件系统控制部分的简单语言，HCL（Hardware Control Language，硬件控制语言）。

### 4.1 Y86-64 指令集体系结构

#### 4.1.3 指令编码

> 程序寄存器存在 CPU 中的一个寄存器文件中，这个寄存器文件就是一个小的、以寄存器 ID 作为地址的随机访问存储器。
>
> x86-64 有时称为”复杂指令集计算机“（CISC），与“精简指令集计算机”（RISC）相对。

#### 4.1.4 Y86-64 异常

> 处理器通常会调用一个异常处理程序（exception handler），这个过程被指定用来处理遇到的某种类型的异常。就像在第 8 章中讲述的，异常处理程序可以被配置成不同的结果，例如，中止程序或调用一个用户自定义的信号处理程序（signal handler）。

#### 4.1.5 Y86-64 程序

> 伪指令（directive）指明应该将代码或数据放在什么位置，以及如何对齐。

~~与 GCC 标准不同，栈从地址 0x200 开始，第一个 `call` 命令应该把回调地址 0x13 放在0x200 位置才对；但此处，栈的使用导致内存地址 0x1f0~0x1f8 发生了变化。~~`call` 命令会先执行 `pushq` 的操作。

#### 4.1.6 一些 Y86-64 指令地详情

当执行

```assembly
pushq %rsp
```

指令时，x86-64 处理器会压入 `%rsp` 地原始值；

> The PUSH ESP instruction pushed the value of the ESP register as it existed before the instruction was executed. If a PUSH instruction uses a memory operand in which the ESP register is used for computing the operand address, the address of the operand is computed before the ESP register is decremented.

当执行

```assembly
popq %rsp
```

指令时，x86-64 处理器会将栈指针设置为从内存中读出来地那个值；

> The POP ESP instruction increments the stack pointer (ESP) before data at the old top of stack is written into the destination.[^1]

### 4.2 逻辑设计和硬件控制语言 HCL

> 要实现一个数字系统需要三个主要地组成部分：计算对位进行操作地函数地组合逻辑、存储位地存储器单元，以及控制存储器单元更新地时钟信号。
>
> 现在，大多数电路设计都是用硬件描述语言（Hardware Description Language，HDL）来表达地。HDL 是一种文本表示，看上去和编程语言类似，但是它是用来描述硬件结构而不是程序行为的。最常用地语言是 Verilog，它地语法类似于 C；另一种是 VHDL，它地语法类似于编程语言 Ada。

#### 4.2.3 字级的组合电路和 HCL 整数表达式

> 在 HCL 中，多路复用函数是用情况表达式（case expression）来描述的。我们不要求不同的表达式之间互斥。从逻辑上讲，这些选择表达式是顺序求值的，且第一个求值为 1 的情况会被选中。允许不互斥的选择表达式使得 HCL 代码的可读性更好。实际的硬件多路复用器的信号必须互斥，它们要控制哪个输入字应该被传送到输出。

就像练习题 4.12 的答案一样，表达式可以将“或”的条件放在两行，就像没有 break 的 switch 一样的。

```verilog
word Med3 = [
    A <= B && B <= C : B;
    C <= B && B <= A : B;
    B <= A && A <= C : A;
    C <= A && A <= B : A;
    1                : C;
]
```

#### 4.2.5 存储器和时钟

> 存储设备都是由同一个时钟控制的，时钟是一个周期性信号，决定什么时候要把新值加载到设备中。考虑两类存储器设备：
>
> - 时钟寄存器（简称寄存器）存储单个位或字。时钟信号控制寄存器加载输入值。
> - 随机访问存储器（简称内存）存储多个字，用地址来选择该读或该写哪个字。随机访问存储器的例子包括：1）处理器的虚拟内存系统，硬件和操作系统软件结合起来使处理器可以在一个很大的地址空间内访问任意的字；2）寄存器文件，在此，寄存器标识符作为地址。
>
> 一个很自然的问题就是“如果我们试图同时读和写同一个寄存器会发生什么？”答案简单明了：如果更新一个寄存器，同时在读端口上用同一个寄存器 ID，我们会看到一个从旧值到新值的变化。

### 4.3 Y86-64 的顺序实现

#### 4.3.1 将处理组织成阶段

> 下面是关于各个阶段以及各阶段内执行操作的简略描述：
>
> - 取指（fetch）：取指阶段从内存读取指令字节，地址为程序计数器（PC）的值。从指令中抽取出指令指示符字节的两个四位部分，称为 icode（指令代码）和 ifun（指令功能）。它可能取出一个寄存器指示符字节，指明了一个或两个寄存器操作数指示符 rA 和 rB。它还可能取出一个四字节常数字 `valC`。它按顺序方式计算当前指令的下一条指令的地址 `valP`。也就是说，valP 等于 PC 的值加上已取出指令的长度。
> - 译码（decode）：译码阶段从寄存器文件读入最多两个操作数，得到值 `valA` 和/或 `valB`。通常，它读入指令 rA 和 rB字段指明的寄存器，不过有些指令是读寄存器 %rsp 的。
> - 执行（execute）：在执行阶段，算术/逻辑单元（ALU）要么执行指令指明的操作（根据 ifun 的值），计算内存引用的有效地址，要么增加或减少栈指针。得到的值我们称为 `valE`。在此，也可能设置条件码。对一条条件传送指令来说，这个阶段会检验条件码和传送条件（由 ifun 给出），如果条件成立，则更新目标寄存器。同样，对一条跳转指令来说，这个阶段会决定是不是应该选择分支。
> - 访存（memory）：访存阶段可以将数据写入内存，或者从内存读出数据。读出的值为 `valM`。
> - 写回（write back）：写回阶段最多可以写两个结果到寄存器文件。
> - 更新 PC（PC update）：将 PC 设置成下一条指令的地址。

`rrmovq`、`irmovq` 指令在执行阶段基本都执行了将数据与 0 相加的操作，~~可能是为了与 `OPq` 指令保持一致，在写回阶段使用 valE 地值~~；

#### 4.3.2 SEQ 硬件结构

以 SEQ 的硬件结构为例：

- ALU 的输入端口 A 由 `valC` 或者寄存器 `valA` 作为输入；
- ALU 的输入端口 B 由 `valB` 作为输入；
- 数据内存的地址端口由 `valE` 或者 `valA` 作为输入；
- 数据内存的数据端口由 `valP` 或者 `valA` 作为输入；
- 寄存器文件数据端口 A 可以作为 ALU A 的输入或者数据内存的地址和数据端口的输入；`rmmoveq`、`pushq`、`popq`、`ret` 指令中，`valA` 可以直接输入数据内存中；
- 寄存器文件数据端口 B 只可以作为 ALU B 的输入；
- 寄存器文件数据端口 E 由 `valE` 作为输入，所以 `rrmovq` 和 `irmovq` 的数据 `valA` 和 `valC` 不能直接作为寄存器文件的输入，得通过 ALU 输出 `valE` 传入到寄存器文件端口 E 中；
- 寄存器文件地址端口 dstE 由 `rB` 作为输入，也就是计算出来 `valE` 的会存于地址 `rB`；
- 寄存器文件数据端口 M 由 `valM` 作为输入，所以一次寄存器文件可以满足修改两个寄存器的值；
- 寄存器文件地址端口 dstM 由 `rA` 作为输入，也就是访存得到的 `valM` 的会存于地址 `rA`；
- 新 PC 由 `valC`、`valM` 和 `valP` 作为输入；

#### 4.3.3 SEQ 的时序

以文中 Y86-64 模型为例：

> 原则：从不回读
>
> 处理器从来不需要为了完成一条指令的执行而去读由该指令更新了的状态。

- 程序计数器 PC 保持输出 64 位高低电压（表示一个地址）；

- 指令内存以 PC 作为输入，并在短暂延时（远远小于一个时钟周期）后，保持输出对应的高低电压；

  寄存器文件的读、算术逻辑单元都是一个逻辑组合；

- 如果有整数运算，算术逻辑单元会修改对条件码的输出电压，但条件码是一个时钟寄存器，条件码在下一个时钟上升沿前都保持原有的输出电压；

- 数据内存、寄存器文件的写、程序计数器 PC 都是时钟寄存器，计算完成后，它们的输入电压产生相应的改变，等待下一个时钟上升沿就将数据写入；

- 一个周期结束，时钟上升沿；

- 程序计数器 PC 和条件码的输出更新为其输入，整个组合逻辑的电压都会在短暂延时后产生相应的新变化（新轮回）；数据将写入数据内存和寄存器文件；

### 4.4 流水线的通用原理

> 流水线化的一个重要特性就是提高了系统的吞吐量（throughput），也就是单位时间内服务的顾客总数，不过它也会轻微地增加延迟（latency），也就是服务一个用户所需要地时间。

#### 4.4.1 计算流水线

> 在现在逻辑设计中，电路延迟以微微秒或皮秒（picosecond，简写成”ps”），也就是10^-12秒为单位来计算。下面这个公式给出了运行这个系统的最大吞吐量：
> $$
> 吞吐量 = \frac{1条指令}{(20+300)ps}\cdot\frac{1000ps}{lns}\approx3.12GIPS
> $$
> lns = 10^-9s
>
> 我们以每秒千兆条指令（GIPS），也就是每秒十亿条指令，为单位描述吞吐量。从头到尾执行一条指令所需要的时间称为延迟（latency）。在此系统中，延迟为 320ps，也就是吞吐量的倒数。

图 4-33 中计算被划分为三个阶段，对应组合逻辑 A、组合逻辑 B 和组合逻辑 C；流水线中，左侧纵坐标代表的是指令 I1、指令 I2、指令 I3 进入某个组合逻辑的流水线图；

#### 4.4.3 流水线的局限性

不幸的是，会出现其他一些因素，降低流水线的效率。

##### 1. 不一致的划分

> 由不一致的阶段延迟造成的流水线技术的局限性。系统的吞吐量受最慢阶段的速度所限制。
>
> 理解时序优化在实际系统设计中的重要性还是非常重要的。

延迟不是所有阶段的时间总和，应该是子阶段中最大的延迟乘以阶段个数；因为所有阶段都必须等待最慢的子阶段完成才可以切换；

吞吐量也受最慢的子阶段延迟影响，为最慢的子阶段延迟的倒数；

##### 2. 流水线过深，收益反而下降

> 由开销造成的流水线技术的局限性。在组合逻辑被分成较小的块时，由寄存器更新引起的延迟就成为了一个限制因素。
>
> 为了提高时钟频率，现代处理器采用了很深的（15或更多的阶段）流水线。处理器架构师将指令的执行划分成很多非常简单的步骤，这样一来每个阶段的延迟就很小。电路设计者小心地设计流水线寄存器，使其延迟尽可能得小。芯片设计者也必须小心地设计时钟传播网络，以保证时钟在整个芯片上同时改变。所有这些都是设计高速微处理器面临地挑战。

### 4.5 Y86-64 的流水线实现

#### 4.5.1 SEQ+：重新安排计算阶段

> SEQ 到 SEQ+ 中对状态单元的改变是一种很通用的改进的例子，这种改进称为电路重定时。重定时改变了一个系统的状态标识，但是并不改变它的逻辑行为。通常用它来平衡一个流水线系统中各个阶段之间的延迟。

#### 4.5.3 对信号进行重新排列和标号

> 作为一条通用原则，我们要保存处于一个流水线阶段中的指令的所有信息。
>
> 在硬件设计中，像这样仔细确认信号是如何使用的，然后通过合并信号来减少寄存器状态和线路的数量，是很常见的。

#### 4.5.4 预测下一个 PC

> 猜测分支方向并根据猜测开始取值的技术称为分支预测。
>
> **分支预测策略**
>
> 我们的设计使用总是选择（always taken）分支的预测策略。研究表明这个策略的成功率大约是 60%。相反，从不选择（never taken，NT）策略的成功率大约为 40%。稍微复杂一点的是反向选择、正向不选择（backward taken，forward not-taken，BTFNT）策略，当分支地址比下一条地址低时就预测选择分支，而分支地址比较高时，就预测不选择分支。这种策略的成功率大约为 65%。这种改进源自一个事实，即循环时由后向分支结束的，而循环通常会执行多次。前向分支用于条件操作，而这种选择的可能性比较小。
>
> 分支预测错误会极大地降低程序地性能，因此这就促使我们在可能的时候，要使用条件数据传送而不是控制转移。
>
> **使用栈的返回地址预测**
>
> 对大多数程序来说，预测返回值很容易，因为过程调用和返回是成对出现的。大多数函数调用，会返回到调用后的那条指令。高性能处理器中运用了这个属性，在取指单元中放入一个硬件栈，保存过程调用指令产生的返回地址。每次执行过程调用指令时，都将其返回地址压入栈中。当取出一个返回指令时，就从这个栈中弹出顶部的值，作为预测的返回值。同分支预测一样，在预测错误时必须提供一个恢复机制，因为还是有调用和返回不匹配的时候。通常，这种预测很可靠。这个硬件栈对程序员来说时不可见的。

#### 4.5.5 流水线冒险

> 将流水线技术引入一个带反馈的系统，当相邻指令间存在相关时会导致出现问题。这些相关有两种形式：1）数据相关，下一条指令会用到这一条指令计算出的结果；2）控制相关，一条指令要确定下一条指令的位置，例如在执行跳转，调用或返回指令时。这些相关可能会导致流水线产生计算错误，称为冒险（hazard）。同相关一样，冒险也可以分为两类：数据冒险（data hazard）和控制冒险（control hazard）。

##### 1. 用暂停来避免数据冒险

> 暂停（stalling）是避免冒险的一种常用技术，暂停时，处理器会停止流水线中一条或多条指令，直到冒险条件不再满足。让一条指令停顿在译码阶段，直到产生它的源操作数的指令通过了写回阶段，这样我们的处理器就能避免数据冒险。
>
> 暂停技术就是让一组指令阻塞在它们所处的阶段，而允许其他指令继续通过流水线。每次要把一条指令阻塞在译码阶段，就在执行阶段插入一个气泡。气泡就像一个自动产生的 `nop` 指令——它不会改变寄存器、内存、条件码或程序状态。
>
> 虽然实现这一机制相当容易，但是得到的性能并不很好。一条指令更新一个寄存器，紧跟其后的指令就是用被更新的寄存器，像这样的情况不胜枚举。这会导致流水线暂停长达三个周期，严重降低了整体的吞吐量。

译码阶段动态插入的 `nop` 指令气泡会自动在下一个周期填补访存和写回阶段；

##### 2. 用转发避免数据冒险

> 与其暂停直到写完成，不如简单地将要写地值传到流水线寄存器 E 作为源操作数。
>
> 这种将结果值直接从一个流水线阶段传到较早阶段地技术称为数据转发（data forwarding，或简称转发，有时称为旁路（bypassing））。
>
> 这样一共就有五个不同的转发源（`e_valE`、`m_valM`、`M_valE`、`W_valM` 和 `W_valE`），以及两个不同的转发目的（`valA` 和 `valB`）。
>
> 编译阶段逻辑能够确定是使用来自寄存器文件得值，还是要用转发过来得值。与每个要写回寄存器文件得值相关得是目的寄存器 ID。逻辑会将这些 ID 与源寄存器 ID srcA 和 srcB 相比较，以此来检测是否需要转发。可能有多个目的寄存器 ID 与一个源 ID 相等。要解决这样的情况，我们必须在各个转发源中建立起优先级关系。

主要矛盾是指令在译码阶段值 `valA` 和 `valB` 的值，在之前的指令中被修改了还未保存；通过将以下的值，直接转发过来，从而避免了暂停。

- e_valE

  数据位于执行阶段，通过 ALU 得出数据；

- m_valM

  数据位于访存阶段，通过内存中取出的数据；

- M_valE

  数据位于访存阶段，通过 ALU 得出数据，但位于 M 寄存器上；

- W_valM

  数据位于写回阶段，通过内存中取出的数据，但位于 W 寄存器上；

- W_valE

  数据位于写回阶段，通过 ALU 得出的数据，但位于 W 寄存器上；

##### 3. 加载/使用数据冒险

> 有一类数据冒险不能单纯用转发来解决，因为内存读在流水线发生的比较晚。
>
> 我们可以将暂停和转发结合起来，避免加载/使用数据冒险。这种用暂停来处理加载/使用冒险的方法称为加载互锁（load interlock）。加载互锁和转发技术结合起来足以处理所有可能类型的数据冒险。因为只有加载互锁会降低流水线的吞吐量，我们几乎可以实现每个时钟周期发射一条新指令的吞吐量目标。

##### 4. 避免控制冒险

> 当处理器无法根据处于取指阶段的当前指令来确定下一条指令的地址时，就会出现控制冒险。

处理方式是将 `call` 指令的写回阶段对齐新指令的取指阶段；在此不使用 `m_valM` 而将 `call` 指令访存阶段对齐新指令的取指阶段是因为，只转发到译码阶段，而取指阶段的值是通过写回阶段的寄存器取得的；

> 处理预测错误的分支指令。流水线预测会选择分支，所以开始取跳转目标初的指令。在周期 4 发现预测错误之前，已经取出了两条指令，此时，跳转指令正在通过执行阶段。在周期 5 中，流水线往译码和执行阶段中插入气泡，取消了两条目标指令，同时还取出跳转后面那条指令。这样就能取消（有时也称为指令排除（instruction squashing））那两条预测错误的指令。这样一来，两条预测错误的指令就会简单地从流水线中消失，因此不会对程序员可见地状态产生影响。唯一地缺点是两个时钟周期的指令处理能力被浪费了。

#### 4.5.6 异常处理

> 异常可以由程序执行从内部产生，也可以由某个外部信号从外部产生。一个更完整的处理器设计应该也能处理外部异常，例如当处理器收到一个网络接口收到新包的信号，或是一个用户点击鼠标按钮的信号。正确处理异常是任何微处理器设计中很有挑战性的一方面。异常可能出现在不可预测的时间，需要明确地中断通过处理器流水线地指令流。
>
> 在一个流水线化的系统中，异常处理包括一些细节问题。首先，可能同时有多条指令会引起异常。基本原则是：由流水线中最深的指令引起的异常，优先级最高。第二个细节问题是，当首先取出一条指令，开始执行时，导致了一个异常，而后来由于分支预测错误，取消了该指令。第三个细节问题的产生是因为流水线化的处理器会在不同的阶段更新系统状态的不同部分。有可能会出现这样的情况，一条指令导致了一个异常，它后面的指令在异常指令完成之前改变了部分状态。
>
> 当流水线中有一个或多个阶段出现异常时，信息只是简单地存放在流水线寄存器的状态字段中。异常事件不会对流水线中地指令流有任何影响，除了会禁止流水线中后面的指令更新程序员可见的状态（条件码寄存器和内存），直到异常指令到达最后的流水线阶段。因为指令到达写回阶段的顺序与它们在非流水线化的处理器中执行的顺序相同，所以我们可以保证第一条遇到异常的指令会第一个到达写回阶段，此时程序会执行停止，流水线寄存器 W 中的状态码会被记录为程序状态。如果取出了某条指令，过后又取消了，那么所有关于这条指令的异常状态信息也会被取消。所有导致异常的指令后面的指令都不能改变程序员可见的状态。携带指令的异常状态以及所有其他信息通过流水线的简单原则是处理异常的简单而可靠的机制。

~~还是没有回答访存地址错误时，如何及时禁止执行阶段去修改状态码；~~访存地址错误异常还得等到写回阶段才提交异常，那么不能改变状态码的执行阶段还得再留一个时钟周期了；

##### 4.5.7 PIPE 各阶段的实现

##### 1. PC 选择和取指阶段

> PC 选择逻辑从三个程序计数器源中进行选择。当一条预测错误的分支进入访存阶段时，会从流水线寄存器 M（信号 M_valA）中读出该指令 valP 的值（指明下一条指令的地址）。当 ret 指令进入写回阶段时，会从流水线寄存器 W（信号 W_valM）中读出返回地址。其他情况会使用存放在流水线寄存器 F（信号 F_predPC）中的 PC 的预测值。

##### 2. 译码和写回阶段

> 上述 HCL 代码中赋予这 5 个转发源的优先级是非常重要的。这种优先级是由 HCL 代码中检测 5 个目的寄存器 ID 的顺序来确定。如果选择了其他任何顺序，对某些程序来说，流水线就会出错。流水线化的实现应该总是给处于最早流水线阶段中的转发源以较高的优先级，因为它保持着程序序列中设置该寄存器的最近的指令。因此，上述 HCL 代码中的逻辑首先会检测执行阶段中的转发源，然后是访存阶段，最后才是写回阶段。只有指令 popq %rsp 会关心在访存或写回阶段中的两个源之间的转发优先级，因为只有这条指令能同时写两个寄存器。

增加了一个 `SBUB` 气泡状态的状态常量；

#### 4.5.8 流水线控制逻辑

##### 1. 特殊控制情况所期望的处理

> 对于导致异常的指令，我们必须使流水线化的实现符合期望的 ISA 行为，也就是在前面所有的指令结束前，后面的指令不能影响程序的状态。一些因素会使得想达到这些效果比较麻烦：1）异常在程序执行的两个不同阶段（取指和访存）被发现的，2）程序状态在三个不同阶段（执行、访存和写回）被更新。
>
> 在我们的阶段设计中，每个流水线寄存器中会包含一个状态码 stat，随着每条指令经过流水线阶段，它会记录指令的状态。当异常发生时，我们将这个信息作为指令状态的一部分记录下来，并且继续取指、译码和执行指令，就好像什么都没有出错似的。当异常指令到达访存阶段时，我们会采取措施防止后面的指令修改程序员可见的状态：1）禁止执行阶段中的指令设置条件码，2）向内存阶段中插入气泡，以禁止向数据内存中写入，3）当写回阶段中有异常指令时，暂停写回阶段，因而暂停了流水线。

##### 3. 流水线控制机制

如图 4-66 所示，逻辑应该是：

- 处理 ret

  遇到 ret 后面指令需要暂停 3 个周期，当后一指令来到取指阶段后，流水线控制逻辑执行取指阶段暂停，并在译码阶段补一个气泡；因为要停 3 个周期，所以后一个周期还需要重复一次，让后一条指令停留在取指阶段；

- 加载/使用冒险

  在译码阶段需要读取的寄存器的值，需要从内存中取出，所以等该指令进入到译码阶段周期后，流水线控制逻辑使取指（等待访存指令更新值的下一条指令）和译码阶段暂停，并在执行阶段补一个气泡；

- 预测错误的分支

  预测分支会将预测地址的指令运行两个周期，也就是最深到达译码阶段而不会改变任何状态；如果此时发现是错误的预测分支，流水线控制逻辑将正确的指令放入取指阶段（取指阶段是正常的），将强两条错误的指令该进入的阶段 （译码和运行阶段）补入气泡，消除它们的影响；

#### 4.5.9 性能分析

> 我们可以通过计算 PIPE 执行一条指令所需要的平均时钟周期数的估计值，来量化这些处罚对整体性能的影响，这种衡量方法称为 CPI（Cycles per Instruction，每指令周期数）。这种衡量值是流水线平均吞吐量的倒数，不过时间单位是时钟周期，而不是微微秒。这是一个设计体系结构效率的很有用的衡量标准。
>
> 每个周期，执行阶段要么会处理一条指令，然后这条指令继续通过剩下的阶段，直到完成；要么会处理一个由于三种特殊情况之一而插入的气泡。如果这个阶段一共处理了 C~i~ 条指令和 C~b~ 个气泡，那么处理器总共需要大约 C~i~ + C~b~ 个时钟来执行 C~i~ 条指令。我们说”大约“是因为忽略了启动指令通过流水线的周期。于是，可以用如下方法来计算这个基准的 CPI：
> $$
> CPI = \frac{C_i + C_b}{C_i} = 1.0 + \frac{C_b}{C+i}
> $$
> 也就是说，CPI 等于 1.0 加上一个处罚项 C~b~/C~i~，这个项表明执行一条指令平均要插入多少个气泡。

#### 4.5.10 未完成的工作

##### 1. 多周期指令

> 通过采用独立于流水线的特殊硬件功能单元来处理较为复杂的操作，可以得到更好的性能。通常，有一个功能单元来执行整数乘法和除法，还有一个来执行浮点操作。当一条指令进入译码阶段时，它可以被发射到特殊单元。在这个特殊单元执行该操作时，流水线会继续处理其他指令。通常，浮点单元本身也是流水线化的，因此多条指令可以在主流水线和各个单元中并发执行。
>
> 不同单元的操作必须同步，以避免出错。

##### 2. 与存储系统的接口

> 处理器的存储系统是由多种硬件存储器和管理虚拟内存的操作系统软件共同组成的。一个典型的高速缓存存储器有两个第一层高速缓存——一个用于读指令，一个用于读和写数据。另一种类型的高速缓存存储器，称为翻译后备缓冲器（Translation Look-aside Buffer，TLB），它提供了从虚拟地址到物理地址的快速翻译。将 TLB 和高速缓存结合起来使用，在大多数时候，确实可能在一个时钟周期内读指令并读或是写数据。
>
> 有时候高速缓存不命中（miss），可以从较高层的高速缓存或处理器的主存中找到不命中的数据，这需要 3~20 个时钟周期。同事，流水线会简单的暂停，将指令保持在取指或访存阶段，直到高速缓存能够执行读或写操作。高速缓存不命中以及随之而来的与流水线的同步完全是由硬件来处理的，这样能使所需的时间尽可能地缩短到很少数量地时钟周期。
>
> 有些情况中，被引用的存储器位置实际上使存储在磁盘存储器上的。此时，硬件会产生一个缺页（page fault）异常信号。同其他异常一样，这个异常会导致处理器调用操作系统的异常处理程序代码。然后这段代码会发起一个从磁盘到主存的传送操作。一旦完成，操作系统会返回原来的程序，而导致缺页的指令会被重新执行。这次，存储器引用将成功，虽然可能会导致高速缓存不命中。让硬件调用操作系统例程，然后操作系统例程又会将控制返回给硬件，这就使得硬件和系统软件在处理缺页时能协同工作。因为访问磁盘需要数百万个时钟周期，OS 缺页中断处理程序执行的处理所需的几百个时钟周期对性能的影响可以忽略不计。
>
> 从处理器的角度来看，将用暂停处理短时间的高速缓存不命中和用异常处理来处理长时间的缺页结合起来，能够顾及到存储器访问时由于存储器层次结构引起的所有不可预测性。

当前的微处理器设计

> 较新的处理器支持超标量（superscaler）操作，意味着它们通过并行地取指、译码和执行多条指令，可以实现小于 1.0 的 CPI。当超标量处理器已经广泛使用时，性能测量标准已经从 CPI 转化成了它的倒数——每周期执行指令的平均数，即 IPC。对超标量处理器来说，IPC 可以大于 1.0。最先进的设计使用了一种成为乱序（out-of-order）执行的技术来并行地执行多条指令，执行地顺序也可能完全不同于它们在程序中出现地顺序，但是保留了顺序 ISA 模型蕴含地整体行为。

[^1]:<Intel 64 and IA-32 Architectures Software Developer's Manual Volume 2: Instruction Set Reference, A-Z>
